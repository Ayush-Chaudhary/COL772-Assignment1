{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from time import time\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./Desktop/nlp_a1/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"./Desktop/nlp_a1/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "Stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1(txt):\n",
    "    txt = txt.lower() \n",
    "    txt = punctuation.sub(' ', txt)\n",
    "    text = BAD_SYMBOLS_RE.sub('', txt) \n",
    "    txt = ' '.join(word for word in txt.split() if word not in Stopwords) # delete stopwors from text\n",
    "    return txt\n",
    "\n",
    "def preprocess2(txt):\n",
    "    txt = txt.lower() \n",
    "    txt = punctuation.sub(' ', txt)\n",
    "    text = BAD_SYMBOLS_RE.sub('', txt) \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['profile']=data['profile'].apply(preprocess1)\n",
    "# data1['profile']=data1['profile'].apply(preprocess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['profession'].value_counts()\n",
    "data['profile'].apply(lambda x: len(x.split(' '))).sum()\n",
    "data['profession'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.DataFrame(columns=['profile','profession'])\n",
    "data_val=pd.DataFrame(columns=['profile','profession'])\n",
    "data_test=pd.DataFrame(columns=['profile','profession'])\n",
    "\n",
    "data=data.sample(frac=1, random_state=143).reset_index()\n",
    "\n",
    "prof=data['profession'].unique()\n",
    "a=0\n",
    "for i in prof:\n",
    "    df=data[data['profession']==i].reset_index().drop(columns=['index'])\n",
    "    rows=int(df.shape[0]/10)\n",
    "    f=df.shape[0]-rows*10\n",
    "    l1=[i for i in range(0,rows*8+f)]\n",
    "    l2=[i for i in range(rows*8+f,rows*9+f)]\n",
    "    l3=[i for i in range(rows*9+f,df.shape[0])]\n",
    "    df1=df.filter(items=l1,axis=0)\n",
    "    df2=df.filter(items=l2,axis=0)\n",
    "    df3=df.filter(items=l3,axis=0)\n",
    "    data_train=pd.concat([data_train,df1], ignore_index=True)\n",
    "    data_val=pd.concat([data_val,df2], ignore_index=True)\n",
    "    data_test=pd.concat([data_test,df3], ignore_index=True)\n",
    "data_train=data_train.sample(frac=1, random_state=143).reset_index()\n",
    "data_val=data_val.sample(frac=1, random_state=143).reset_index()\n",
    "data_test=data_test.sample(frac=1, random_state=143).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=data_train.profile,data_train.profession\n",
    "X_val,y_val=data_val.profile,data_val.profession\n",
    "X_test,y_test=data_test.profile,data_test.profession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.profile\n",
    "y = data.profession\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state = 1667)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state = 1667)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier for Multinomial Models\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "my_tags=data['profession'].unique().tolist()\n",
    "# %%time\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          teacher       0.82      0.72      0.77       196\n",
      "        professor       0.76      0.60      0.67       329\n",
      "         attorney       0.85      0.90      0.87      1058\n",
      "          surgeon       0.93      0.59      0.72        73\n",
      "     photographer       0.82      0.71      0.76       103\n",
      "          painter       0.77      0.84      0.80       188\n",
      "     psychologist       0.87      0.94      0.90       432\n",
      "        filmmaker       0.83      0.80      0.81       137\n",
      "        physician       0.83      0.72      0.77        47\n",
      "interior_designer       0.80      0.78      0.79       227\n",
      "        architect       0.75      0.46      0.57        46\n",
      "        dietitian       0.68      0.72      0.70       640\n",
      "           pastor       0.82      0.77      0.80       231\n",
      "           rapper       0.87      0.77      0.82       589\n",
      "       journalist       0.75      0.78      0.77       245\n",
      "          dentist       1.00      0.42      0.59        57\n",
      "       accountant       0.55      0.61      0.58        76\n",
      "             poet       0.76      0.71      0.73        58\n",
      "            model       0.82      0.88      0.85       820\n",
      "            nurse       0.85      0.86      0.86      1276\n",
      "     chiropractor       0.72      0.73      0.72       205\n",
      "     yoga_teacher       0.84      0.91      0.87      3937\n",
      "software_engineer       0.82      0.73      0.77       582\n",
      "        paralegal       0.71      0.66      0.68        41\n",
      "         composer       0.68      0.64      0.66       209\n",
      " personal_trainer       0.85      0.66      0.74       384\n",
      "         comedian       0.65      0.52      0.58       541\n",
      "               dj       0.70      0.76      0.73        59\n",
      "\n",
      "         accuracy                           0.81     12786\n",
      "        macro avg       0.79      0.72      0.75     12786\n",
      "     weighted avg       0.81      0.81      0.81     12786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stocastic Gradient Classifier\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# sgd = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "#                 #('tfidf', TfidfTransformer()),\n",
    "#                 ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=50, tol=None)),\n",
    "#                ])\n",
    "\n",
    "# a=time()\n",
    "# sgd.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_train = sgd.predict(X_train)\n",
    "# print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "# y_pred = sgd.predict(X_test)\n",
    "# print('test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    \n",
    "# b=time()\n",
    "# print(b-a)\n",
    "my_tags=data['profession'].unique()\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "\n",
    "rfc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 1))),\n",
    "                #('tfidf', TfidfTransformer()),\n",
    "                ('clf', RandomForestClassifier(max_depth=80, verbose=2)),\n",
    "               ])\n",
    "\n",
    "a=time()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_train = rfc.predict(X_train)\n",
    "print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "y_pred = rfc.predict(X_test)\n",
    "print('test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "b=time()\n",
    "print(b-a)\n",
    "\n",
    "my_tags=data['profession'].unique()\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost Classifier\n",
    "\n",
    "abc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 1))),\n",
    "                #('tfidf', TfidfTransformer()),\n",
    "                ('clf', AdaBoostClassifier()),\n",
    "               ])\n",
    "\n",
    "a=time()\n",
    "abc.fit(X_train, y_train)\n",
    "y_pred_train = abc.predict(X_train)\n",
    "print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "y_pred = abc.predict(X_test)\n",
    "print('test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "b=time()\n",
    "print(b-a)\n",
    "\n",
    "my_tags=data['profession'].unique()\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "a= time()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "def get_pipe(c):\n",
    "    logreg = Pipeline([('vect', CountVectorizer(ngram_range=(1, 1))),\n",
    "                    ('clf', LogisticRegression(n_jobs=1,C=c, verbose=2, max_iter=500)),\n",
    "                   ])\n",
    "    return logreg\n",
    "c=[1,100,1e4,1e6]\n",
    "for i in c:\n",
    "    logreg=get_pipe(i)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    print('c =', i)\n",
    "    y_pred_train = abc.predict(X_train)\n",
    "    print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "    y_pred = abc.predict(X_test)\n",
    "    print('test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "b=time()\n",
    "print(b-a)\n",
    "\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "gbc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2))),\n",
    "                #('tfidf', TfidfTransformer()),\n",
    "                ('clf', GradientBoostingClassifier()),\n",
    "               ])\n",
    "\n",
    "a=time()\n",
    "gbc.fit(X_train, y_train)\n",
    "y_pred_train = gbc.predict(X_train)\n",
    "print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "y_pred = gbc.predict(X_test)\n",
    "print('test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "b=time()\n",
    "print(b-a)\n",
    "\n",
    "my_tags=data['profession'].unique()\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Linear Support Vector Classifier\n",
    "\n",
    "def get_pipe(c):\n",
    "    lsvc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))),\n",
    "                    ('clf', LinearSVC(verbose=2, class_weight='balanced', C=c, max_iter=10000)),\n",
    "                   ])\n",
    "    return lsvc\n",
    "\n",
    "my_tags=data['profession'].unique()\n",
    "\n",
    "a=time()\n",
    "lis=[0.04]\n",
    "for i in lis:\n",
    "    lsvc=get_pipe(i)\n",
    "    lsvc.fit(X_train, y_train)\n",
    "    print('c =',i)\n",
    "    y_pred_train = lsvc.predict(X_train)\n",
    "    print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "    y_pred = lsvc.predict(X_val)\n",
    "    print('test accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "    print(classification_report(y_val, y_pred,target_names=my_tags))\n",
    "b=time()\n",
    "print(b-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Support Vector Classifier with equal split\n",
    "\n",
    "def get_pipe(c):\n",
    "    lsvc = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))),\n",
    "                    ('clf', LinearSVC(verbose=1, class_weight='balanced', C=c, max_iter=10000)),\n",
    "                   ])\n",
    "    return lsvc\n",
    "\n",
    "my_tags=data['profession'].unique()\n",
    "\n",
    "a=time()\n",
    "lis=[0.04]\n",
    "for i in lis:\n",
    "    lsvc=get_pipe(i)\n",
    "    lsvc.fit(X_train, y_train)\n",
    "    print('c =',i)\n",
    "    y_pred_train = lsvc.predict(X_train)\n",
    "    print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "    y_pred = lsvc.predict(X_val)\n",
    "    print('test accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "    print(classification_report(y_val, y_pred,target_names=my_tags))\n",
    "b=time()\n",
    "print(b-a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 123155)\t1\n",
      "  (0, 111350)\t1\n",
      "  (0, 20118)\t1\n",
      "  (0, 34490)\t1\n",
      "  (0, 106984)\t1\n",
      "  (0, 141966)\t1\n",
      "  (0, 68065)\t2\n",
      "  (0, 71411)\t4\n",
      "  (0, 34953)\t1\n",
      "  (0, 122074)\t1\n",
      "  (0, 47644)\t1\n",
      "  (0, 40881)\t1\n",
      "  (0, 100744)\t1\n",
      "  (0, 125580)\t1\n",
      "  (0, 45239)\t1\n",
      "  (0, 103990)\t1\n",
      "  (0, 140053)\t1\n",
      "  (0, 122035)\t1\n",
      "  (0, 141521)\t1\n",
      "  (0, 24364)\t1\n",
      "  (0, 60702)\t1\n",
      "  (0, 111725)\t1\n",
      "  (0, 31027)\t1\n",
      "  (0, 48855)\t1\n",
      "  (0, 53238)\t1\n",
      "  :\t:\n",
      "  (103560, 63673)\t1\n",
      "  (103560, 84117)\t1\n",
      "  (103560, 106186)\t1\n",
      "  (103560, 51851)\t2\n",
      "  (103560, 142616)\t1\n",
      "  (103560, 134818)\t1\n",
      "  (103560, 103291)\t1\n",
      "  (103560, 129350)\t1\n",
      "  (103560, 51622)\t1\n",
      "  (103560, 10557)\t2\n",
      "  (103560, 99996)\t1\n",
      "  (103560, 3755)\t1\n",
      "  (103560, 18003)\t1\n",
      "  (103560, 110896)\t1\n",
      "  (103560, 124402)\t1\n",
      "  (103561, 71411)\t1\n",
      "  (103561, 128817)\t1\n",
      "  (103561, 45541)\t1\n",
      "  (103561, 113106)\t1\n",
      "  (103561, 10404)\t2\n",
      "  (103561, 82755)\t4\n",
      "  (103561, 122036)\t1\n",
      "  (103561, 25594)\t1\n",
      "  (103561, 97591)\t1\n",
      "  (103561, 20986)\t1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 112. GiB for an array with shape (103562, 144970) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_vec)\n\u001b[0;32m      9\u001b[0m X_csr \u001b[38;5;241m=\u001b[39m csr_matrix(X_vec)\n\u001b[1;32m---> 10\u001b[0m X_dense \u001b[38;5;241m=\u001b[39m \u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_dense)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:864\u001b[0m, in \u001b[0;36mspmatrix.todense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtodense\u001b[39m(\u001b[38;5;28mself\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m    Return a dense matrix representation of this matrix.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m        `numpy.matrix` object that shares the same memory.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asmatrix(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:1039\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1038\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1039\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:1202\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 112. GiB for an array with shape (103562, 144970) and data type int64"
     ]
    }
   ],
   "source": [
    "# Stocastic Gradient Classifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "vect=CountVectorizer(ngram_range=(1, 1))\n",
    "X_vec=vect.fit_transform(X_train)\n",
    "print(X_vec)\n",
    "\n",
    "X_csr = csr_matrix(X_vec)\n",
    "X_dense = X_csr.todense()\n",
    "print(X_dense)\n",
    "\n",
    "# sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=50, tol=None)\n",
    "\n",
    "\n",
    "# a=time()\n",
    "# sgd.fit(X_dense, y_train)\n",
    "\n",
    "# y_pred_train = sgd.predict(X_train)\n",
    "# print('train accuracy %s' % accuracy_score(y_pred_train, y_train))\n",
    "# y_pred = sgd.predict(X_test)\n",
    "# print('test accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "    \n",
    "# b=time()\n",
    "# print(b-a)\n",
    "# my_tags=data['profession'].unique()\n",
    "\n",
    "# print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1f857a0a901882a24647502651452ecc56651e20fc2ac0f59654ba8490358db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
